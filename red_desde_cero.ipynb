{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My red desde cero.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fbelinchon/ml/blob/master/red_desde_cero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-wpY4KvFVz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcPVHY3PFnmT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "#from exp.nb_02 import *\n",
        "import torch.nn.functional as F\n",
        "from pathlib import Path\n",
        "from IPython.core.debugger import set_trace\n",
        "from fastai import datasets\n",
        "import pickle, gzip, math, torch, matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import tensor\n",
        "import torch.nn as nn\n",
        "\n",
        "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6PIkz0-JhmA",
        "colab_type": "text"
      },
      "source": [
        "# Creamos el modelo de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqCepTOYFwng",
        "colab_type": "text"
      },
      "source": [
        "## **Creamos el dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfa5xzqbFzHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Dataset():\n",
        "    def __init__(self, x,y):\n",
        "        self.x=x\n",
        "        self.y=y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        return self.x[i],self.y[i]\n",
        "   \n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZxofzsWHiJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def get_data():\n",
        "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
        "    with gzip.open(path, 'rb') as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
        "    return map(tensor, (x_train,y_train,x_valid,y_valid))\n",
        "\n",
        "def normalize(x, m, s): return (x-m)/s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz06aCxiHys9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7a08fe8a-7432-4118-8db9-0e803cb69b63"
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://deeplearning.net/data/mnist/mnist.pkl.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfQh4vCSHzZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds,valid_ds=Dataset(x_train,y_train),Dataset(x_valid,y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXKT7C6LIwCi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "923b4349-532a-4519-ddd4-06934cc78b5a"
      },
      "source": [
        "x,y=train_ds[5]\n",
        "plt.imshow(x.view(28,28))\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7nKf0yJJp_a",
        "colab_type": "text"
      },
      "source": [
        "## Creamos el DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjgKIunUK_84",
        "colab_type": "text"
      },
      "source": [
        "Creamos un DataLoader para poder extraer información del Dataset en paquetes con tamaño batch size (bs).\n",
        "Utilizamos yield para devolver un Generator para el batch indicado. <BR>\n",
        "De esta forma podemos obtener un Iterador para cada batch.<BR>\n",
        "  __iter__ itera por cada batch y lo que devuelve te permite recorrer los elementos de ese batch en concreto. El for nos devuelve cada uno del los batch al iterar sobre el Dataloader. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGfT3NipJslw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataLoader():\n",
        "    def __init__(self,ds,bs):\n",
        "        self.ds,self.bs=ds,bs\n",
        "    def __iter__(self):\n",
        "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq4Ld2DFOUaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl=DataLoader(train_ds,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw4rM02lOdvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "c1d9b7a3-eefa-447b-a2c8-542a0fb8db89"
      },
      "source": [
        "i=0\n",
        "for x,y in train_dl:  \n",
        "    i=i+1\n",
        "    print(y)\n",
        "    if (i==4): break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])\n",
            "tensor([3, 5, 3, 6, 1, 7, 2, 8, 6, 9])\n",
            "tensor([4, 0, 9, 1, 1, 2, 4, 3, 2, 7])\n",
            "tensor([3, 8, 6, 9, 0, 5, 6, 0, 7, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD4VaRNwUCid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CM4u2Y2qSVJQ",
        "colab_type": "text"
      },
      "source": [
        "## Muestreo aleatorio en los batch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSfiwUICXkeN",
        "colab_type": "text"
      },
      "source": [
        "    En cada Epoch hay que obtener batch con diferentes ejemplos. \n",
        "    Para ello vamos a utilizar la clase DataLoader de Pytorch que permite indicar si queremos valores aleatorios de batch en cada epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQh24m7DXRqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnCQLcjtX_uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DataLoader??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QujSCJpkO9q_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl=DataLoader(train_ds,32,True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaVcxVlSTJjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_dl=DataLoader(valid_ds,32,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsxKyhb7UDar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "3834d71d-18b6-4fd4-d43c-2fbd6f132bfe"
      },
      "source": [
        "i=0\n",
        "for x,y in train_dl:  \n",
        "    i=i+1\n",
        "    print(y)\n",
        "    if (i==4): break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([6, 5, 0, 5, 8, 4, 6, 2, 6, 1, 1, 0, 1, 2, 9, 8, 3, 1, 9, 6, 6, 4, 2, 8,\n",
            "        3, 1, 4, 8, 2, 6, 2, 6])\n",
            "tensor([1, 2, 9, 2, 8, 8, 5, 4, 0, 4, 0, 1, 1, 1, 5, 8, 4, 9, 3, 1, 2, 9, 5, 6,\n",
            "        2, 0, 2, 2, 1, 1, 7, 7])\n",
            "tensor([6, 9, 0, 8, 0, 8, 4, 8, 1, 1, 0, 2, 4, 5, 4, 5, 8, 5, 1, 4, 1, 7, 9, 0,\n",
            "        3, 7, 1, 7, 1, 3, 6, 2])\n",
            "tensor([3, 3, 2, 9, 1, 1, 1, 5, 3, 2, 9, 8, 9, 8, 9, 5, 8, 7, 7, 2, 3, 8, 1, 6,\n",
            "        8, 9, 3, 6, 3, 3, 4, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o_tGNllUEHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSebNPLNnF34",
        "colab_type": "text"
      },
      "source": [
        "# Inicio del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGh8_9QKkZ1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dl=DataLoader(train_ds,32,True)\n",
        "valid_dl=DataLoader(valid_ds,32,False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdNEZ2Y9nIBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo = nn.Sequential(\n",
        "    nn.Linear(784,100),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(100,50))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN0hJz8epDuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epo=5\n",
        "optimi=torch.optim.Adam(modelo.parameters(),lr=1e-3)\n",
        "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1-5iYIopF0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epoch,model,loss_funcion,optimizer,train_dl,valid_dl):\n",
        "    for ep in range(epoch):\n",
        "        tot_loss,tot_acc = 0.,0.\n",
        "        vtot_loss,vtot_acc = 0.,0.\n",
        "        for x,y in train_dl:\n",
        "\n",
        "            out=model(x)\n",
        "            loss = loss_funcion(out,y)\n",
        "            with torch.no_grad():\n",
        "                tot_loss += loss\n",
        "                tot_acc  += accuracy(out,y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        nv = len(train_dl)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for x,y in valid_dl:\n",
        "\n",
        "                out=modelo(x)\n",
        "                vtot_loss += F.cross_entropy(out,y)\n",
        "                vtot_acc  += accuracy(out,y)\n",
        "\n",
        "        vnv = len(valid_dl)    \n",
        "        print('Error '+str(tot_loss/nv)+' Accuracy ' + str(tot_acc/nv)+' Error validación '+ str(vtot_loss/vnv) +' Accuracy validación ' + str(vtot_acc/vnv))\n",
        "    \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrHE5uuOpGgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "9f0512c7-b9c7-47dc-869e-94a4a0758770"
      },
      "source": [
        "fit(10,modelo,F.cross_entropy,optimi,train_dl,valid_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error tensor(0.3742) Accuracy tensor(0.8979) Error validación tensor(0.1980) Accuracy validación tensor(0.9444)\n",
            "Error tensor(0.1768) Accuracy tensor(0.9478) Error validación tensor(0.1500) Accuracy validación tensor(0.9587)\n",
            "Error tensor(0.1246) Accuracy tensor(0.9642) Error validación tensor(0.1137) Accuracy validación tensor(0.9680)\n",
            "Error tensor(0.0934) Accuracy tensor(0.9725) Error validación tensor(0.1086) Accuracy validación tensor(0.9689)\n",
            "Error tensor(0.0740) Accuracy tensor(0.9778) Error validación tensor(0.1055) Accuracy validación tensor(0.9693)\n",
            "Error tensor(0.0589) Accuracy tensor(0.9822) Error validación tensor(0.0938) Accuracy validación tensor(0.9743)\n",
            "Error tensor(0.0475) Accuracy tensor(0.9857) Error validación tensor(0.1022) Accuracy validación tensor(0.9728)\n",
            "Error tensor(0.0394) Accuracy tensor(0.9883) Error validación tensor(0.0911) Accuracy validación tensor(0.9746)\n",
            "Error tensor(0.0318) Accuracy tensor(0.9902) Error validación tensor(0.0919) Accuracy validación tensor(0.9747)\n",
            "Error tensor(0.0270) Accuracy tensor(0.9918) Error validación tensor(0.0895) Accuracy validación tensor(0.9769)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMQTNQz6pU2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "e05ce3d0-b592-40b1-9831-466b63cd445c"
      },
      "source": [
        "\n",
        "plt.imshow(valid_dl.dataset.x[91 ].view(28,28))\n",
        "torch.argmax(modelo(valid_dl.dataset.x[91 ]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBf7Mk8sZU_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f00c5d95-badc-4c72-e546-915a6ad363e3"
      },
      "source": [
        "for i in range(len(valid_dl.dataset.x)):\n",
        "    out=torch.argmax(modelo(valid_dl.dataset.x[i]))\n",
        "    y=valid_dl.dataset.y[i]\n",
        "    if(out != y): print('Indice '+str(i)+' valor y ' + str(y)+' predición '+str(out))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indice 5 valor y tensor(4) predición tensor(9)\n",
            "Indice 91 valor y tensor(5) predición tensor(4)\n",
            "Indice 120 valor y tensor(1) predición tensor(7)\n",
            "Indice 144 valor y tensor(9) predición tensor(4)\n",
            "Indice 212 valor y tensor(3) predición tensor(8)\n",
            "Indice 239 valor y tensor(9) predición tensor(0)\n",
            "Indice 246 valor y tensor(8) predición tensor(3)\n",
            "Indice 322 valor y tensor(5) predición tensor(3)\n",
            "Indice 329 valor y tensor(9) predición tensor(7)\n",
            "Indice 346 valor y tensor(8) predición tensor(1)\n",
            "Indice 415 valor y tensor(6) predición tensor(1)\n",
            "Indice 417 valor y tensor(3) predición tensor(5)\n",
            "Indice 426 valor y tensor(7) predición tensor(1)\n",
            "Indice 428 valor y tensor(6) predición tensor(0)\n",
            "Indice 431 valor y tensor(3) predición tensor(2)\n",
            "Indice 446 valor y tensor(2) predición tensor(8)\n",
            "Indice 473 valor y tensor(9) predición tensor(7)\n",
            "Indice 500 valor y tensor(3) predición tensor(8)\n",
            "Indice 514 valor y tensor(8) predición tensor(3)\n",
            "Indice 522 valor y tensor(9) predición tensor(8)\n",
            "Indice 714 valor y tensor(8) predición tensor(3)\n",
            "Indice 747 valor y tensor(9) predición tensor(8)\n",
            "Indice 753 valor y tensor(2) predición tensor(3)\n",
            "Indice 819 valor y tensor(4) predición tensor(9)\n",
            "Indice 821 valor y tensor(8) predición tensor(9)\n",
            "Indice 841 valor y tensor(4) predición tensor(9)\n",
            "Indice 881 valor y tensor(5) predición tensor(3)\n",
            "Indice 917 valor y tensor(4) predición tensor(7)\n",
            "Indice 994 valor y tensor(7) predición tensor(3)\n",
            "Indice 1054 valor y tensor(3) predición tensor(9)\n",
            "Indice 1106 valor y tensor(3) predición tensor(5)\n",
            "Indice 1164 valor y tensor(8) predición tensor(3)\n",
            "Indice 1230 valor y tensor(3) predición tensor(5)\n",
            "Indice 1248 valor y tensor(9) predición tensor(4)\n",
            "Indice 1274 valor y tensor(3) predición tensor(5)\n",
            "Indice 1280 valor y tensor(9) predición tensor(4)\n",
            "Indice 1298 valor y tensor(5) predición tensor(6)\n",
            "Indice 1346 valor y tensor(7) predición tensor(9)\n",
            "Indice 1356 valor y tensor(2) predición tensor(1)\n",
            "Indice 1398 valor y tensor(2) predición tensor(3)\n",
            "Indice 1414 valor y tensor(8) predición tensor(9)\n",
            "Indice 1432 valor y tensor(1) predición tensor(3)\n",
            "Indice 1544 valor y tensor(1) predición tensor(3)\n",
            "Indice 1600 valor y tensor(4) predición tensor(9)\n",
            "Indice 1698 valor y tensor(2) predición tensor(1)\n",
            "Indice 1740 valor y tensor(5) predición tensor(0)\n",
            "Indice 1764 valor y tensor(5) predición tensor(2)\n",
            "Indice 1780 valor y tensor(4) predición tensor(9)\n",
            "Indice 1794 valor y tensor(5) predición tensor(9)\n",
            "Indice 1944 valor y tensor(4) predición tensor(9)\n",
            "Indice 1988 valor y tensor(7) predición tensor(4)\n",
            "Indice 1990 valor y tensor(5) predición tensor(3)\n",
            "Indice 1993 valor y tensor(6) predición tensor(5)\n",
            "Indice 2048 valor y tensor(0) predición tensor(6)\n",
            "Indice 2085 valor y tensor(3) predición tensor(5)\n",
            "Indice 2106 valor y tensor(5) predición tensor(0)\n",
            "Indice 2129 valor y tensor(3) predición tensor(5)\n",
            "Indice 2140 valor y tensor(4) predición tensor(2)\n",
            "Indice 2144 valor y tensor(2) predición tensor(7)\n",
            "Indice 2163 valor y tensor(6) predición tensor(4)\n",
            "Indice 2166 valor y tensor(7) predición tensor(9)\n",
            "Indice 2218 valor y tensor(8) predición tensor(6)\n",
            "Indice 2225 valor y tensor(2) predición tensor(4)\n",
            "Indice 2236 valor y tensor(9) predición tensor(4)\n",
            "Indice 2241 valor y tensor(8) predición tensor(9)\n",
            "Indice 2279 valor y tensor(4) predición tensor(9)\n",
            "Indice 2280 valor y tensor(8) predición tensor(9)\n",
            "Indice 2394 valor y tensor(3) predición tensor(5)\n",
            "Indice 2548 valor y tensor(2) predición tensor(3)\n",
            "Indice 2674 valor y tensor(6) predición tensor(0)\n",
            "Indice 2686 valor y tensor(5) predición tensor(3)\n",
            "Indice 2707 valor y tensor(7) predición tensor(9)\n",
            "Indice 2834 valor y tensor(2) predición tensor(3)\n",
            "Indice 2854 valor y tensor(1) predición tensor(6)\n",
            "Indice 2894 valor y tensor(2) predición tensor(1)\n",
            "Indice 2899 valor y tensor(7) predición tensor(3)\n",
            "Indice 2914 valor y tensor(5) predición tensor(0)\n",
            "Indice 2932 valor y tensor(8) predición tensor(3)\n",
            "Indice 2953 valor y tensor(2) predición tensor(8)\n",
            "Indice 2968 valor y tensor(8) predición tensor(2)\n",
            "Indice 2975 valor y tensor(2) predición tensor(0)\n",
            "Indice 2981 valor y tensor(5) predición tensor(6)\n",
            "Indice 3063 valor y tensor(5) predición tensor(6)\n",
            "Indice 3098 valor y tensor(1) predición tensor(8)\n",
            "Indice 3112 valor y tensor(8) predición tensor(0)\n",
            "Indice 3114 valor y tensor(5) predición tensor(9)\n",
            "Indice 3156 valor y tensor(3) predición tensor(2)\n",
            "Indice 3216 valor y tensor(9) predición tensor(0)\n",
            "Indice 3470 valor y tensor(5) predición tensor(0)\n",
            "Indice 3476 valor y tensor(4) predición tensor(9)\n",
            "Indice 3507 valor y tensor(5) predición tensor(8)\n",
            "Indice 3556 valor y tensor(8) predición tensor(3)\n",
            "Indice 3578 valor y tensor(6) predición tensor(5)\n",
            "Indice 3638 valor y tensor(5) predición tensor(0)\n",
            "Indice 3680 valor y tensor(9) predición tensor(7)\n",
            "Indice 3806 valor y tensor(8) predición tensor(9)\n",
            "Indice 3872 valor y tensor(8) predición tensor(3)\n",
            "Indice 3873 valor y tensor(4) predición tensor(9)\n",
            "Indice 3906 valor y tensor(8) predición tensor(0)\n",
            "Indice 3953 valor y tensor(8) predición tensor(3)\n",
            "Indice 3999 valor y tensor(8) predición tensor(0)\n",
            "Indice 4011 valor y tensor(7) predición tensor(2)\n",
            "Indice 4032 valor y tensor(6) predición tensor(0)\n",
            "Indice 4074 valor y tensor(3) predición tensor(5)\n",
            "Indice 4136 valor y tensor(8) predición tensor(9)\n",
            "Indice 4178 valor y tensor(8) predición tensor(5)\n",
            "Indice 4180 valor y tensor(8) predición tensor(3)\n",
            "Indice 4191 valor y tensor(3) predición tensor(2)\n",
            "Indice 4195 valor y tensor(8) predición tensor(3)\n",
            "Indice 4264 valor y tensor(4) predición tensor(1)\n",
            "Indice 4296 valor y tensor(3) predición tensor(8)\n",
            "Indice 4327 valor y tensor(8) predición tensor(3)\n",
            "Indice 4378 valor y tensor(7) predición tensor(3)\n",
            "Indice 4452 valor y tensor(4) predición tensor(9)\n",
            "Indice 4458 valor y tensor(1) predición tensor(6)\n",
            "Indice 4506 valor y tensor(1) predición tensor(2)\n",
            "Indice 4576 valor y tensor(1) predición tensor(6)\n",
            "Indice 4586 valor y tensor(9) predición tensor(1)\n",
            "Indice 4623 valor y tensor(7) predición tensor(9)\n",
            "Indice 4757 valor y tensor(8) predición tensor(9)\n",
            "Indice 4834 valor y tensor(2) predición tensor(1)\n",
            "Indice 4858 valor y tensor(3) predición tensor(5)\n",
            "Indice 4878 valor y tensor(4) predición tensor(8)\n",
            "Indice 4880 valor y tensor(5) predición tensor(6)\n",
            "Indice 4885 valor y tensor(6) predición tensor(4)\n",
            "Indice 4949 valor y tensor(5) predición tensor(1)\n",
            "Indice 4950 valor y tensor(8) predición tensor(9)\n",
            "Indice 4954 valor y tensor(8) predición tensor(5)\n",
            "Indice 4994 valor y tensor(6) predición tensor(0)\n",
            "Indice 5060 valor y tensor(5) predición tensor(3)\n",
            "Indice 5102 valor y tensor(9) predición tensor(4)\n",
            "Indice 5128 valor y tensor(8) predición tensor(0)\n",
            "Indice 5168 valor y tensor(6) predición tensor(8)\n",
            "Indice 5240 valor y tensor(9) predición tensor(4)\n",
            "Indice 5264 valor y tensor(8) predición tensor(9)\n",
            "Indice 5311 valor y tensor(8) predición tensor(7)\n",
            "Indice 5330 valor y tensor(8) predición tensor(5)\n",
            "Indice 5340 valor y tensor(4) predición tensor(1)\n",
            "Indice 5368 valor y tensor(8) predición tensor(9)\n",
            "Indice 5374 valor y tensor(7) predición tensor(9)\n",
            "Indice 5418 valor y tensor(4) predición tensor(9)\n",
            "Indice 5438 valor y tensor(8) predición tensor(3)\n",
            "Indice 5677 valor y tensor(3) predición tensor(9)\n",
            "Indice 5729 valor y tensor(5) predición tensor(3)\n",
            "Indice 5739 valor y tensor(5) predición tensor(6)\n",
            "Indice 5804 valor y tensor(5) predición tensor(2)\n",
            "Indice 5886 valor y tensor(5) predición tensor(6)\n",
            "Indice 5896 valor y tensor(7) predición tensor(2)\n",
            "Indice 5906 valor y tensor(2) predición tensor(3)\n",
            "Indice 5958 valor y tensor(5) predición tensor(9)\n",
            "Indice 6014 valor y tensor(5) predición tensor(3)\n",
            "Indice 6054 valor y tensor(5) predición tensor(9)\n",
            "Indice 6066 valor y tensor(7) predición tensor(1)\n",
            "Indice 6180 valor y tensor(8) predición tensor(2)\n",
            "Indice 6220 valor y tensor(7) predición tensor(9)\n",
            "Indice 6224 valor y tensor(5) predición tensor(9)\n",
            "Indice 6268 valor y tensor(4) predición tensor(9)\n",
            "Indice 6292 valor y tensor(9) predición tensor(1)\n",
            "Indice 6312 valor y tensor(2) predición tensor(3)\n",
            "Indice 6313 valor y tensor(8) predición tensor(9)\n",
            "Indice 6344 valor y tensor(5) predición tensor(9)\n",
            "Indice 6346 valor y tensor(7) predición tensor(2)\n",
            "Indice 6372 valor y tensor(2) predición tensor(0)\n",
            "Indice 6380 valor y tensor(4) predición tensor(9)\n",
            "Indice 6397 valor y tensor(0) predición tensor(2)\n",
            "Indice 6452 valor y tensor(4) predición tensor(1)\n",
            "Indice 6464 valor y tensor(9) predición tensor(3)\n",
            "Indice 6480 valor y tensor(9) predición tensor(3)\n",
            "Indice 6586 valor y tensor(5) predición tensor(8)\n",
            "Indice 6590 valor y tensor(2) predición tensor(3)\n",
            "Indice 6596 valor y tensor(4) predición tensor(9)\n",
            "Indice 6774 valor y tensor(9) predición tensor(4)\n",
            "Indice 6824 valor y tensor(2) predición tensor(7)\n",
            "Indice 6842 valor y tensor(8) predición tensor(9)\n",
            "Indice 6866 valor y tensor(8) predición tensor(5)\n",
            "Indice 6890 valor y tensor(5) predición tensor(3)\n",
            "Indice 6914 valor y tensor(0) predición tensor(7)\n",
            "Indice 7041 valor y tensor(0) predición tensor(9)\n",
            "Indice 7076 valor y tensor(4) predición tensor(1)\n",
            "Indice 7082 valor y tensor(4) predición tensor(9)\n",
            "Indice 7216 valor y tensor(8) predición tensor(3)\n",
            "Indice 7276 valor y tensor(8) predición tensor(3)\n",
            "Indice 7327 valor y tensor(5) predición tensor(3)\n",
            "Indice 7380 valor y tensor(7) predición tensor(9)\n",
            "Indice 7486 valor y tensor(0) predición tensor(8)\n",
            "Indice 7510 valor y tensor(5) predición tensor(9)\n",
            "Indice 7532 valor y tensor(8) predición tensor(9)\n",
            "Indice 7608 valor y tensor(3) predición tensor(2)\n",
            "Indice 7624 valor y tensor(2) predición tensor(8)\n",
            "Indice 7628 valor y tensor(2) predición tensor(0)\n",
            "Indice 7662 valor y tensor(5) predición tensor(6)\n",
            "Indice 7713 valor y tensor(4) predición tensor(9)\n",
            "Indice 7718 valor y tensor(7) predición tensor(1)\n",
            "Indice 7728 valor y tensor(9) predición tensor(5)\n",
            "Indice 7731 valor y tensor(8) predición tensor(9)\n",
            "Indice 7744 valor y tensor(9) predición tensor(4)\n",
            "Indice 7880 valor y tensor(9) predición tensor(7)\n",
            "Indice 7882 valor y tensor(0) predición tensor(9)\n",
            "Indice 7972 valor y tensor(4) predición tensor(9)\n",
            "Indice 8022 valor y tensor(1) predición tensor(7)\n",
            "Indice 8048 valor y tensor(3) predición tensor(5)\n",
            "Indice 8064 valor y tensor(3) predición tensor(9)\n",
            "Indice 8080 valor y tensor(3) predición tensor(2)\n",
            "Indice 8094 valor y tensor(7) predición tensor(3)\n",
            "Indice 8101 valor y tensor(4) predición tensor(1)\n",
            "Indice 8236 valor y tensor(9) predición tensor(4)\n",
            "Indice 8246 valor y tensor(6) predición tensor(2)\n",
            "Indice 8539 valor y tensor(9) predición tensor(7)\n",
            "Indice 8560 valor y tensor(0) predición tensor(3)\n",
            "Indice 8648 valor y tensor(7) predición tensor(1)\n",
            "Indice 8653 valor y tensor(5) predición tensor(8)\n",
            "Indice 8802 valor y tensor(5) predición tensor(3)\n",
            "Indice 8871 valor y tensor(5) predición tensor(9)\n",
            "Indice 9081 valor y tensor(3) predición tensor(9)\n",
            "Indice 9289 valor y tensor(1) predición tensor(3)\n",
            "Indice 9297 valor y tensor(1) predición tensor(3)\n",
            "Indice 9354 valor y tensor(1) predición tensor(8)\n",
            "Indice 9401 valor y tensor(4) predición tensor(9)\n",
            "Indice 9460 valor y tensor(1) predición tensor(8)\n",
            "Indice 9653 valor y tensor(0) predición tensor(9)\n",
            "Indice 9701 valor y tensor(5) predición tensor(6)\n",
            "Indice 9718 valor y tensor(8) predición tensor(5)\n",
            "Indice 9719 valor y tensor(9) predición tensor(5)\n",
            "Indice 9720 valor y tensor(2) predición tensor(0)\n",
            "Indice 9726 valor y tensor(5) predición tensor(3)\n",
            "Indice 9731 valor y tensor(5) predición tensor(6)\n",
            "Indice 9747 valor y tensor(5) predición tensor(6)\n",
            "Indice 9763 valor y tensor(8) predición tensor(5)\n",
            "Indice 9825 valor y tensor(3) predición tensor(9)\n",
            "Indice 9915 valor y tensor(4) predición tensor(7)\n",
            "Indice 9934 valor y tensor(0) predición tensor(4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN3e2wk7Z5wB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "af0fc5c9-72f6-4d2b-8a01-02f135c05d04"
      },
      "source": [
        "modelo\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=50, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjTlY-tqnAjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nATYYgyvc0Vv",
        "colab_type": "text"
      },
      "source": [
        "#Mejora de diseño de clases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBESdrbUkRmJ",
        "colab_type": "text"
      },
      "source": [
        "Definimos una función para devolver un DataLoader para train y valid.<br>\n",
        "para train generamos índices aleatorios mientras que para el conjunto de validación no tiene sentido.<br>\n",
        "También pasamos **kwargs para poder pasar todos los parámetros adicionales a la clase DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wcLQICAjx2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
        "    return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n",
        "            DataLoader(valid_ds, batch_size=bs*2, **kwargs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8mAS-AUc2e4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "class DataBunch():\n",
        "    def __init__(self, train_dl, valid_dl, c=None):\n",
        "        self.train_dl,self.valid_dl,self.c = train_dl,valid_dl,c\n",
        "        \n",
        "    @property\n",
        "    def train_ds(self): return self.train_dl.dataset\n",
        "        \n",
        "    @property\n",
        "    def valid_ds(self): return self.valid_dl.dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9_IPE0doZ8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_valid,y_valid = get_data()\n",
        "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
        "nh,bs = 50,32\n",
        "c = y_train.max().item()+1\n",
        "loss_func = F.cross_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDq6YjiNdcOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=DataBunch(train_dl,valid_dl,c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8-fot4-kbI0",
        "colab_type": "text"
      },
      "source": [
        "Creamos una función para devolver el modelo y el optimizador.<br>\n",
        "Además la clase Learner que simplemente agrupa todos los objetos necesarios para ejecutar la función fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-o2rDCymkgha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def get_model(data, lr=0.5, nh=100):\n",
        "    m = data.train_ds.x.shape[1]\n",
        "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,data.c))\n",
        "    return model, optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "class Learner():\n",
        "    def __init__(self, model, opt, loss_func, data):\n",
        "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxbvFHTcpaiP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "a4c19498-5b8d-4608-acbd-9f3a25f29822"
      },
      "source": [
        "get_model(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Sequential(\n",
              "   (0): Linear(in_features=784, out_features=100, bias=True)\n",
              "   (1): ReLU()\n",
              "   (2): Linear(in_features=100, out_features=10, bias=True)\n",
              " ), Adam (\n",
              " Parameter Group 0\n",
              "     amsgrad: False\n",
              "     betas: (0.9, 0.999)\n",
              "     eps: 1e-08\n",
              "     lr: 0.5\n",
              "     weight_decay: 0\n",
              " ))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2RFBwlYfSjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner=Learner(*get_model(data,lr=1e-3),loss_func,data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsaChkZeiwpc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epoch,learner):\n",
        "    for ep in range(epoch):\n",
        "        tot_loss,tot_acc = 0.,0.\n",
        "        vtot_loss,vtot_acc = 0.,0.\n",
        "        for x,y in learner.data.train_dl:\n",
        "\n",
        "            out=learner.model(x)\n",
        "            loss = learner.loss_func(out,y)\n",
        "            with torch.no_grad():\n",
        "                tot_loss += loss\n",
        "                tot_acc  += accuracy(out,y)\n",
        "\n",
        "            loss.backward()\n",
        "            learner.opt.step()\n",
        "            learner.opt.zero_grad()\n",
        "        nv = len(learner.data.train_dl)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for x,y in learner.data.valid_dl:\n",
        "\n",
        "                out=learner.model(x)\n",
        "                vtot_loss += learner.loss_func(out,y)\n",
        "                vtot_acc  += accuracy(out,y)\n",
        "\n",
        "        vnv = len(learner.data.valid_dl)    \n",
        "        print('Epoch '+str(ep)+' Error '+str(tot_loss/nv)+' Accuracy ' + str(tot_acc/nv)+' Error validación '+ str(vtot_loss/vnv) +' Accuracy validación ' + str(vtot_acc/vnv))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxaOQkZSrBDO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "472671a8-c752-485c-814a-af7b9a6877e5"
      },
      "source": [
        "fit(16,learner)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Error tensor(0.3387) Accuracy tensor(0.9063) Error validación tensor(0.1904) Accuracy validación tensor(0.9475)\n",
            "Epoch 1 Error tensor(0.1639) Accuracy tensor(0.9514) Error validación tensor(0.1362) Accuracy validación tensor(0.9596)\n",
            "Epoch 2 Error tensor(0.1138) Accuracy tensor(0.9671) Error validación tensor(0.1082) Accuracy validación tensor(0.9685)\n",
            "Epoch 3 Error tensor(0.0857) Accuracy tensor(0.9748) Error validación tensor(0.0940) Accuracy validación tensor(0.9719)\n",
            "Epoch 4 Error tensor(0.0674) Accuracy tensor(0.9797) Error validación tensor(0.0915) Accuracy validación tensor(0.9728)\n",
            "Epoch 5 Error tensor(0.0544) Accuracy tensor(0.9832) Error validación tensor(0.0950) Accuracy validación tensor(0.9726)\n",
            "Epoch 6 Error tensor(0.0437) Accuracy tensor(0.9866) Error validación tensor(0.0896) Accuracy validación tensor(0.9745)\n",
            "Epoch 7 Error tensor(0.0368) Accuracy tensor(0.9891) Error validación tensor(0.0883) Accuracy validación tensor(0.9758)\n",
            "Epoch 8 Error tensor(0.0297) Accuracy tensor(0.9909) Error validación tensor(0.0909) Accuracy validación tensor(0.9741)\n",
            "Epoch 9 Error tensor(0.0250) Accuracy tensor(0.9925) Error validación tensor(0.0895) Accuracy validación tensor(0.9762)\n",
            "Epoch 10 Error tensor(0.0201) Accuracy tensor(0.9940) Error validación tensor(0.1063) Accuracy validación tensor(0.9734)\n",
            "Epoch 11 Error tensor(0.0180) Accuracy tensor(0.9948) Error validación tensor(0.1028) Accuracy validación tensor(0.9753)\n",
            "Epoch 12 Error tensor(0.0143) Accuracy tensor(0.9958) Error validación tensor(0.0939) Accuracy validación tensor(0.9766)\n",
            "Epoch 13 Error tensor(0.0124) Accuracy tensor(0.9967) Error validación tensor(0.0991) Accuracy validación tensor(0.9755)\n",
            "Epoch 14 Error tensor(0.0114) Accuracy tensor(0.9965) Error validación tensor(0.1107) Accuracy validación tensor(0.9733)\n",
            "Epoch 15 Error tensor(0.0092) Accuracy tensor(0.9976) Error validación tensor(0.1006) Accuracy validación tensor(0.9755)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUIY7xUOrEz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIlQ4zVc2wlV",
        "colab_type": "text"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSnSKLDiGQvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Learner??\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyTEULGK21jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb;\n",
        "def one_batch(xb,yb,cb):\n",
        "    if not cb.begin_batch(xb,yb): return\n",
        "    loss = cb.learn.loss_func(cb.learn.model(xb),yb)\n",
        "    if not cb.after_loss(loss): return\n",
        "    \n",
        "    loss.backward()        \n",
        "    if cb.after_backward(): cb.learn.opt.step()\n",
        "    if cb.after_step(): cb.learn.opt.zero_grad()\n",
        "    \n",
        "    \n",
        "def all_batches(dl,cb):\n",
        "    for xb,yb in dl:    \n",
        "        one_batch(xb,yb,cb)\n",
        "        if cb.do_stop(): break\n",
        "    return\n",
        "        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DiBWykY6Q-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner=Learner(*get_model(data,lr=1e-3),loss_func,data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXeVRKb13LXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fit(epochs,learn,cb):\n",
        "    if not cb.begin_fit(learn): return\n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        if not cb.begin_epoch(epoch): continue\n",
        "        all_batches(cb.learn.data.train_dl,cb)\n",
        "        \n",
        "        #learn.model.eval()\n",
        "        if cb.begin_validate():\n",
        "             with torch.no_grad(): all_batches(learn.data.valid_dl, cb)\n",
        "        if cb.do_stop() or not cb.after_epoch(): break\n",
        "    cb.after_fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlmH2XiGpcP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nARLUfzO4Om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statistics as st\n",
        "\n",
        "class Callback():\n",
        "    def begin_fit(self, learn):\n",
        "        self.learn = learn\n",
        "        return True\n",
        "    def after_fit(self): return True\n",
        "    def begin_epoch(self, epoch):        \n",
        "        self.epoch=epoch\n",
        "        self.learn.model.train()\n",
        "        return True\n",
        "    def begin_validate(self):\n",
        "        self.learn.model.eval()\n",
        "        return True\n",
        "    def after_epoch(self): \n",
        "        return True\n",
        "    def begin_batch(self, xb, yb):\n",
        "        self.xb,self.yb = xb,yb\n",
        "        return True\n",
        "    def after_loss(self, loss):\n",
        "        self.loss = loss\n",
        "        #return self.learn.model.training\n",
        "        return True\n",
        "    def after_backward(self): return True\n",
        "    def after_step(self): return True\n",
        "    def do_stop(self): return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFEzb8-3_4pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statistics as st\n",
        "\n",
        "class MyCallback(Callback):\n",
        "    \n",
        "    def begin_epoch(self, epoch):\n",
        "        super().begin_epoch(epoch)\n",
        "        self.t_error=[]\n",
        "        self.v_error=[]\n",
        "        self.t_acc=[]\n",
        "        self.v_acc=[]\n",
        "        return True\n",
        "\n",
        "    def after_epoch(self):\n",
        "        \n",
        "        print(f'Training: LOSS {st.mean(self.t_error):.4f} Accuracy: {st.mean(self.t_acc)*100:.2f} Validation LOSS {st.mean(self.v_error):.4f} Accuracy: {st.mean(self.v_acc)*100:.2f}')\n",
        "        return True\n",
        "    def after_loss(self, loss):\n",
        "        self.loss = loss\n",
        "        self.t_error.append(self.loss.item())\n",
        "        if(self.learn.model.training):\n",
        "            self.t_error.append(self.loss.item())\n",
        "            self.t_acc.append(accuracy(self.learn.model(self.xb),self.yb).item())\n",
        "        else:\n",
        "            self.v_error.append(self.loss.item())\n",
        "            self.v_acc.append(accuracy(self.learn.model(self.xb),self.yb).item())\n",
        "        return self.learn.model.training\n",
        "    def after_backward(self): return True\n",
        "    def after_step(self): return True\n",
        "    def do_stop(self): return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58Qs7KwJAeGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback=MyCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUgHKb9s6WyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "c492179e-b8a8-43c9-8c3f-9473a2dc97de"
      },
      "source": [
        "\n",
        "fit(8,learner,callback)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: LOSS 0.2417 Accuracy: 92.87 Validation LOSS 0.1715 Accuracy: 95.33\n",
            "Training: LOSS 0.1444 Accuracy: 95.70 Validation LOSS 0.1245 Accuracy: 96.53\n",
            "Training: LOSS 0.1041 Accuracy: 96.89 Validation LOSS 0.1064 Accuracy: 96.82\n",
            "Training: LOSS 0.0814 Accuracy: 97.60 Validation LOSS 0.0980 Accuracy: 97.23\n",
            "Training: LOSS 0.0656 Accuracy: 98.10 Validation LOSS 0.0881 Accuracy: 97.42\n",
            "Training: LOSS 0.0545 Accuracy: 98.41 Validation LOSS 0.0856 Accuracy: 97.49\n",
            "Training: LOSS 0.0448 Accuracy: 98.77 Validation LOSS 0.0852 Accuracy: 97.59\n",
            "Training: LOSS 0.0385 Accuracy: 98.93 Validation LOSS 0.0854 Accuracy: 97.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKyEfDsy13r0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelo.eval??"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpzueYi_G6Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CallbackHandler():\n",
        "    def __init__(self,cbs=None):\n",
        "        self.cbs = cbs if cbs else []\n",
        "\n",
        "    def begin_fit(self, learn):\n",
        "        self.learn=learn\n",
        "        self.in_train = True\n",
        "        learn.stop = False\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_fit(learn)\n",
        "        return res\n",
        "\n",
        "    def after_fit(self):\n",
        "        res = not self.in_train\n",
        "        for cb in self.cbs: res = res and cb.after_fit()\n",
        "        return res\n",
        "    \n",
        "    def begin_epoch(self, epoch):\n",
        "        self.learn.model.train()\n",
        "        self.in_train=True\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_epoch(epoch)\n",
        "        return res\n",
        "\n",
        "    def begin_validate(self):\n",
        "        print('Begin Validate')\n",
        "        self.learn.model.eval()\n",
        "        self.in_train=False\n",
        "        \n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_validate()\n",
        "        return res\n",
        "\n",
        "    def after_epoch(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_epoch()\n",
        "        return res\n",
        "    \n",
        "    def begin_batch(self, xb, yb):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n",
        "        return res\n",
        "\n",
        "    def after_loss(self, loss):\n",
        "        res = self.in_train\n",
        "        for cb in self.cbs: res = res and cb.after_loss(loss)\n",
        "        return res\n",
        "\n",
        "    def after_backward(self):\n",
        "        \n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_backward()\n",
        "        return res\n",
        "\n",
        "    def after_step(self):\n",
        "        res = True\n",
        "        for cb in self.cbs: res = res and cb.after_step()\n",
        "        return res\n",
        "    \n",
        "    \n",
        "    def do_stop(self):\n",
        "        try:     return self.learn.stop\n",
        "        finally: self.learn.stop = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Peorl0O7Hbap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import statistics\n",
        "\n",
        "class TestCallback(Callback):\n",
        "    def begin_fit(self,learn):\n",
        "        super().begin_fit(learn)\n",
        "        self.n_iters = 0\n",
        "        \n",
        "        return True\n",
        "    def begin_epoch(self,epoch):\n",
        "        super().begin_epoch(epoch)\n",
        "        print('BEGIN Epoch ')\n",
        "        self.t_error = []\n",
        "        self.t_acc = []\n",
        "        self.v_error = []\n",
        "        self.v_acc = []\n",
        "        \n",
        "        return True\n",
        "       \n",
        "    \n",
        "    def after_epoch(self):\n",
        "        self.n_iters = self.n_iters +1\n",
        "        print('Epoch '+str(self.n_iters))\n",
        "        #pdb.set_trace()\n",
        "        #print(f'Validation LOSS {st.mean(self.v_error):.4f} Accuracy: {st.mean(self.v_acc)*100:.2f}')\n",
        "        #print(f'Training: LOSS {st.mean(self.t_error):.4f} Accuracy: {st.mean(self.t_acc)*100:.2f} Validation LOSS {st.mean(self.v_error):.4f} Accuracy: {st.mean(self.v_acc)*100:.2f}')\n",
        "              \n",
        "        return True\n",
        "    \n",
        "                      \n",
        "    def after_loss(self,loss):\n",
        "        #super().after_loss(loss)\n",
        "        #self.n_iters += 1\n",
        "        #print(self.n_iters)\n",
        "        #if self.n_iters>=10: self.learn.stop = True\n",
        "        if(self.learn.model.training): \n",
        "           \n",
        "            self.t_error.append(loss.item())\n",
        "            self.t_acc.append(accuracy(self.learn.model(self.xb),self.yb).item())\n",
        "        else:\n",
        "            if(self.v_error):\n",
        "                print('VAL LOSS')\n",
        "                self.v_error.append(loss.item())\n",
        "                self.v_acc.append(accuracy(self.learn.model(self.xb),self.yb).item())\n",
        "        \n",
        "        return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeGH8aoQmswh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "73dfbf9d-8e3f-432d-adae-71944aee5070"
      },
      "source": [
        "learner.model.eval()\n",
        "print(learner.model.training)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4W4Ob9CHh3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "27b4255b-0054-4e6b-8c89-0b1d39d67d91"
      },
      "source": [
        "#%debug\n",
        "fit(8, learner, cb=CallbackHandler([TestCallback()]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BEGIN Epoch \n",
            "Begin Validate\n",
            "Epoch 1\n",
            "BEGIN Epoch \n",
            "Begin Validate\n",
            "Epoch 2\n",
            "BEGIN Epoch \n",
            "Begin Validate\n",
            "Epoch 3\n",
            "BEGIN Epoch \n",
            "Begin Validate\n",
            "Epoch 4\n",
            "BEGIN Epoch \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-8a5fb3ef12b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCallbackHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTestCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-b3d91db61ae4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, cb)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#learn.model.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-1539aaa056bb>\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(dl, cb)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-1539aaa056bb>\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(xb, yb, cb)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                 \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ls64KBPAdh2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "59162864-4b94-49cf-a7e7-2b9ef3f44f7f"
      },
      "source": [
        "modelo.eval()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=100, out_features=50, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydx30C1ATlu0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9d6bb3f1-5a66-41db-83ef-2e7843ff8595"
      },
      "source": [
        "modelo.train()\n",
        "print(modelo.training)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WpQAF3PTqjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}