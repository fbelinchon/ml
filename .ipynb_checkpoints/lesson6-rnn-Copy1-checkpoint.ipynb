{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:36.267644Z",
     "start_time": "2019-01-07T17:55:35.973757Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to download the collected works of Nietzsche to use as our data for this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:36.549483Z",
     "start_time": "2019-01-07T17:55:36.269659Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH='c:/Users/paco/data/cervantes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:36.854308Z",
     "start_time": "2019-01-07T17:55:36.550491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 2065877\n"
     ]
    }
   ],
   "source": [
    "#get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
    "text = open(f'{PATH}donquijote.txt',encoding='UTF8').read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:37.119163Z",
     "start_time": "2019-01-07T17:55:36.857307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1665877"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2065877-400000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:37.380018Z",
     "start_time": "2019-01-07T17:55:37.122154Z"
    }
   },
   "outputs": [],
   "source": [
    "text_train=text[:1600000]\n",
    "text_test=text[1600000:]\n",
    "text_simple=text[:160000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:37.631861Z",
     "start_time": "2019-01-07T17:55:37.381005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:37.915697Z",
     "start_time": "2019-01-07T17:55:37.632859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 90\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text_train)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's useful to have a zero value in the dataset, e.g. for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:38.177546Z",
     "start_time": "2019-01-07T17:55:37.917696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.01234567:;?ABCDEFGHIJLMNOPQRSTUVWXYZ]abcdefghijlmnopqrstuvxyz¡«»¿ÁÉÍÓÚàáé'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.insert(0, \"\\0\")\n",
    "\n",
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map from chars to indices and back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:38.444409Z",
     "start_time": "2019-01-07T17:55:38.179545Z"
    }
   },
   "outputs": [],
   "source": [
    "char_indices = {c: i for i, c in enumerate(chars)}\n",
    "indices_char = {i: c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:38.701257Z",
     "start_time": "2019-01-07T17:55:38.445391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\x00',\n",
       " 1: '\\n',\n",
       " 2: ' ',\n",
       " 3: '!',\n",
       " 4: '\"',\n",
       " 5: \"'\",\n",
       " 6: '(',\n",
       " 7: ')',\n",
       " 8: ',',\n",
       " 9: '-',\n",
       " 10: '.',\n",
       " 11: '0',\n",
       " 12: '1',\n",
       " 13: '2',\n",
       " 14: '3',\n",
       " 15: '4',\n",
       " 16: '5',\n",
       " 17: '6',\n",
       " 18: '7',\n",
       " 19: ':',\n",
       " 20: ';',\n",
       " 21: '?',\n",
       " 22: 'A',\n",
       " 23: 'B',\n",
       " 24: 'C',\n",
       " 25: 'D',\n",
       " 26: 'E',\n",
       " 27: 'F',\n",
       " 28: 'G',\n",
       " 29: 'H',\n",
       " 30: 'I',\n",
       " 31: 'J',\n",
       " 32: 'L',\n",
       " 33: 'M',\n",
       " 34: 'N',\n",
       " 35: 'O',\n",
       " 36: 'P',\n",
       " 37: 'Q',\n",
       " 38: 'R',\n",
       " 39: 'S',\n",
       " 40: 'T',\n",
       " 41: 'U',\n",
       " 42: 'V',\n",
       " 43: 'W',\n",
       " 44: 'X',\n",
       " 45: 'Y',\n",
       " 46: 'Z',\n",
       " 47: ']',\n",
       " 48: 'a',\n",
       " 49: 'b',\n",
       " 50: 'c',\n",
       " 51: 'd',\n",
       " 52: 'e',\n",
       " 53: 'f',\n",
       " 54: 'g',\n",
       " 55: 'h',\n",
       " 56: 'i',\n",
       " 57: 'j',\n",
       " 58: 'l',\n",
       " 59: 'm',\n",
       " 60: 'n',\n",
       " 61: 'o',\n",
       " 62: 'p',\n",
       " 63: 'q',\n",
       " 64: 'r',\n",
       " 65: 's',\n",
       " 66: 't',\n",
       " 67: 'u',\n",
       " 68: 'v',\n",
       " 69: 'x',\n",
       " 70: 'y',\n",
       " 71: 'z',\n",
       " 72: '¡',\n",
       " 73: '«',\n",
       " 74: '»',\n",
       " 75: '¿',\n",
       " 76: 'Á',\n",
       " 77: 'É',\n",
       " 78: 'Í',\n",
       " 79: 'Ó',\n",
       " 80: 'Ú',\n",
       " 81: 'à',\n",
       " 82: 'á',\n",
       " 83: 'é',\n",
       " 84: 'í',\n",
       " 85: 'ï',\n",
       " 86: 'ñ',\n",
       " 87: 'ó',\n",
       " 88: 'ú',\n",
       " 89: 'ü'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*idx* will be the data we use from now on - it simply converts all the characters to their index (based on the mapping above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:39.064037Z",
     "start_time": "2019-01-07T17:55:38.702244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text_train]\n",
    "\n",
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:55:39.322887Z",
     "start_time": "2019-01-07T17:55:39.065035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Primera parte del ingenioso hidalgo don Quijote de la Mancha   Capítu'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three char model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c1_data = a los caracteres 1,4,7,10 ..... (empieza en 1 y va de 3 en 3)\n",
    "<br>\n",
    "c2_data = a los caracteres en posición 2,5,8 ....\n",
    "<br>\n",
    "c3_data = a las posiciones 3,6,9 ...\n",
    "<br>\n",
    "c4_data = a las posiciones 4,7,10..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:09:09.053148Z",
     "start_time": "2019-01-07T19:09:08.666332Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "cs=10\n",
    "c1_dat = [idx[i]   for i in range(0, len(idx)-cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx)-cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx)-cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx)-cs, cs)]\n",
    "c5_dat = [idx[i+4] for i in range(0, len(idx)-cs, cs)]\n",
    "c6_dat = [idx[i+5] for i in range(0, len(idx)-cs, cs)]\n",
    "c7_dat = [idx[i+6] for i in range(0, len(idx)-cs, cs)]\n",
    "c8_dat = [idx[i+7] for i in range(0, len(idx)-cs, cs)]\n",
    "c9_dat = [idx[i+8] for i in range(0, len(idx)-cs, cs)]\n",
    "c10_dat = [idx[i+9] for i in range(0, len(idx)-cs, cs)]\n",
    "c11_dat = [idx[i+10] for i in range(0, len(idx)-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:08:36.819777Z",
     "start_time": "2019-01-07T19:08:36.550937Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:17:46.056037Z",
     "start_time": "2019-01-07T19:17:45.792176Z"
    }
   },
   "outputs": [],
   "source": [
    "def caracterDefinition(idx,cs):\n",
    "    x=np.ndarray(shape=(int((len(idx)-cs)/cs)+1,cs-1), dtype=int)\n",
    "    #pdb.set_trace()\n",
    "    x[:,0]=[idx[i] for i in range(0, len(idx)-cs, cs)]\n",
    "    \n",
    "    for j in range(1,cs-1):\n",
    "        x[:,j]=[idx[i+j]   for i in range(0, len(idx)-cs, cs)]\n",
    "        \n",
    "        \n",
    "    y=[idx[i+cs] for i in range(0, len(idx)-cs, cs)]\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:17:47.504296Z",
     "start_time": "2019-01-07T19:17:47.215450Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 133333 to array axis with dimension 159999",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-238-4718012f435c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot copy sequence with size 133333 to array axis with dimension 159999"
     ]
    }
   ],
   "source": [
    "x=[idx[i+1] for i in range(0, len(idx)-cs, cs)]\n",
    "y=[idx[i]   for i in range(0, len(idx)-cs, cs)]\n",
    "z[:,0]=x\n",
    "z[:,1]=x\n",
    "z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:17:48.602829Z",
     "start_time": "2019-01-07T19:17:48.168076Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "x,y = caracterDefinition(idx,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:17:49.350391Z",
     "start_time": "2019-01-07T19:17:49.092530Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 2, 36, 64, ...,  2, 51, 52],\n",
       "        [ 2, 56, 60, ..., 48, 58, 54],\n",
       "        [ 2, 51, 61, ..., 52,  2, 58],\n",
       "        ...,\n",
       "        [66, 64, 61, ..., 60, 52, 64],\n",
       "        [49, 58, 52, ..., 67, 52,  2],\n",
       "        [48,  2, 60, ...,  2, 65, 52]]),\n",
       " [2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  48,\n",
       "  70,\n",
       "  59,\n",
       "  67,\n",
       "  48,\n",
       "  58,\n",
       "  2,\n",
       "  48,\n",
       "  67,\n",
       "  68,\n",
       "  58,\n",
       "  66,\n",
       "  66,\n",
       "  2,\n",
       "  2,\n",
       "  59,\n",
       "  64,\n",
       "  82,\n",
       "  70,\n",
       "  82,\n",
       "  61,\n",
       "  62,\n",
       "  67,\n",
       "  50,\n",
       "  1,\n",
       "  52,\n",
       "  58,\n",
       "  51,\n",
       "  2,\n",
       "  48,\n",
       "  65,\n",
       "  59,\n",
       "  51,\n",
       "  55,\n",
       "  58,\n",
       "  61,\n",
       "  48,\n",
       "  49,\n",
       "  8,\n",
       "  52,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  48,\n",
       "  64,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  56,\n",
       "  2,\n",
       "  2,\n",
       "  67,\n",
       "  58,\n",
       "  52,\n",
       "  65,\n",
       "  57,\n",
       "  67,\n",
       "  67,\n",
       "  58,\n",
       "  65,\n",
       "  1,\n",
       "  66,\n",
       "  2,\n",
       "  63,\n",
       "  57,\n",
       "  62,\n",
       "  64,\n",
       "  67,\n",
       "  1,\n",
       "  60,\n",
       "  48,\n",
       "  48,\n",
       "  52,\n",
       "  65,\n",
       "  1,\n",
       "  58,\n",
       "  52,\n",
       "  61,\n",
       "  2,\n",
       "  2,\n",
       "  51,\n",
       "  60,\n",
       "  52,\n",
       "  48,\n",
       "  52,\n",
       "  58,\n",
       "  64,\n",
       "  61,\n",
       "  51,\n",
       "  2,\n",
       "  64,\n",
       "  64,\n",
       "  52,\n",
       "  2,\n",
       "  2,\n",
       "  65,\n",
       "  65,\n",
       "  54,\n",
       "  66,\n",
       "  63,\n",
       "  61,\n",
       "  56,\n",
       "  48,\n",
       "  2,\n",
       "  48,\n",
       "  2,\n",
       "  64,\n",
       "  2,\n",
       "  67,\n",
       "  70,\n",
       "  61,\n",
       "  65,\n",
       "  65,\n",
       "  52,\n",
       "  48,\n",
       "  8,\n",
       "  2,\n",
       "  2,\n",
       "  63,\n",
       "  48,\n",
       "  49,\n",
       "  10,\n",
       "  65,\n",
       "  56,\n",
       "  66,\n",
       "  48,\n",
       "  70,\n",
       "  61,\n",
       "  66,\n",
       "  67,\n",
       "  61,\n",
       "  52,\n",
       "  48,\n",
       "  70,\n",
       "  52,\n",
       "  60,\n",
       "  56,\n",
       "  65,\n",
       "  60,\n",
       "  56,\n",
       "  50,\n",
       "  58,\n",
       "  2,\n",
       "  51,\n",
       "  84,\n",
       "  2,\n",
       "  49,\n",
       "  65,\n",
       "  55,\n",
       "  61,\n",
       "  2,\n",
       "  52,\n",
       "  2,\n",
       "  58,\n",
       "  61,\n",
       "  67,\n",
       "  65,\n",
       "  61,\n",
       "  60,\n",
       "  8,\n",
       "  52,\n",
       "  59,\n",
       "  58,\n",
       "  48,\n",
       "  2,\n",
       "  2,\n",
       "  50,\n",
       "  64,\n",
       "  64,\n",
       "  56,\n",
       "  2,\n",
       "  48,\n",
       "  50,\n",
       "  60,\n",
       "  54,\n",
       "  52,\n",
       "  52,\n",
       "  52,\n",
       "  59,\n",
       "  48,\n",
       "  52,\n",
       "  48,\n",
       "  50,\n",
       "  1,\n",
       "  84,\n",
       "  54,\n",
       "  51,\n",
       "  1,\n",
       "  48,\n",
       "  60,\n",
       "  51,\n",
       "  8,\n",
       "  2,\n",
       "  87,\n",
       "  60,\n",
       "  52,\n",
       "  58,\n",
       "  59,\n",
       "  51,\n",
       "  58,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  50,\n",
       "  48,\n",
       "  65,\n",
       "  60,\n",
       "  52,\n",
       "  52,\n",
       "  58,\n",
       "  8,\n",
       "  60,\n",
       "  50,\n",
       "  53,\n",
       "  63,\n",
       "  2,\n",
       "  52,\n",
       "  59,\n",
       "  49,\n",
       "  8,\n",
       "  64,\n",
       "  60,\n",
       "  56,\n",
       "  66,\n",
       "  2,\n",
       "  2,\n",
       "  51,\n",
       "  2,\n",
       "  48,\n",
       "  61,\n",
       "  2,\n",
       "  61,\n",
       "  50,\n",
       "  10,\n",
       "  24,\n",
       "  2,\n",
       "  48,\n",
       "  61,\n",
       "  60,\n",
       "  58,\n",
       "  8,\n",
       "  52,\n",
       "  2,\n",
       "  64,\n",
       "  2,\n",
       "  65,\n",
       "  2,\n",
       "  52,\n",
       "  55,\n",
       "  51,\n",
       "  68,\n",
       "  60,\n",
       "  52,\n",
       "  2,\n",
       "  2,\n",
       "  58,\n",
       "  59,\n",
       "  48,\n",
       "  63,\n",
       "  67,\n",
       "  56,\n",
       "  2,\n",
       "  52,\n",
       "  58,\n",
       "  52,\n",
       "  61,\n",
       "  2,\n",
       "  65,\n",
       "  59,\n",
       "  2,\n",
       "  58,\n",
       "  65,\n",
       "  2,\n",
       "  63,\n",
       "  59,\n",
       "  2,\n",
       "  67,\n",
       "  83,\n",
       "  60,\n",
       "  56,\n",
       "  58,\n",
       "  2,\n",
       "  51,\n",
       "  53,\n",
       "  65,\n",
       "  51,\n",
       "  48,\n",
       "  52,\n",
       "  60,\n",
       "  63,\n",
       "  68,\n",
       "  61,\n",
       "  52,\n",
       "  61,\n",
       "  56,\n",
       "  8,\n",
       "  61,\n",
       "  62,\n",
       "  50,\n",
       "  49,\n",
       "  2,\n",
       "  64,\n",
       "  63,\n",
       "  48,\n",
       "  49,\n",
       "  65,\n",
       "  65,\n",
       "  52,\n",
       "  62,\n",
       "  56,\n",
       "  61,\n",
       "  1,\n",
       "  59,\n",
       "  60,\n",
       "  2,\n",
       "  48,\n",
       "  62,\n",
       "  56,\n",
       "  60,\n",
       "  66,\n",
       "  2,\n",
       "  68,\n",
       "  67,\n",
       "  65,\n",
       "  52,\n",
       "  66,\n",
       "  2,\n",
       "  55,\n",
       "  60,\n",
       "  48,\n",
       "  48,\n",
       "  51,\n",
       "  48,\n",
       "  65,\n",
       "  1,\n",
       "  2,\n",
       "  56,\n",
       "  2,\n",
       "  61,\n",
       "  68,\n",
       "  2,\n",
       "  2,\n",
       "  48,\n",
       "  61,\n",
       "  59,\n",
       "  65,\n",
       "  67,\n",
       "  61,\n",
       "  2,\n",
       "  57,\n",
       "  60,\n",
       "  56,\n",
       "  60,\n",
       "  67,\n",
       "  52,\n",
       "  2,\n",
       "  52,\n",
       "  65,\n",
       "  52,\n",
       "  70,\n",
       "  2,\n",
       "  71,\n",
       "  50,\n",
       "  2,\n",
       "  50,\n",
       "  56,\n",
       "  49,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  60,\n",
       "  67,\n",
       "  64,\n",
       "  2,\n",
       "  2,\n",
       "  55,\n",
       "  20,\n",
       "  50,\n",
       "  50,\n",
       "  66,\n",
       "  51,\n",
       "  48,\n",
       "  52,\n",
       "  60,\n",
       "  64,\n",
       "  2,\n",
       "  2,\n",
       "  8,\n",
       "  65,\n",
       "  2,\n",
       "  2,\n",
       "  60,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  60,\n",
       "  60,\n",
       "  2,\n",
       "  51,\n",
       "  61,\n",
       "  52,\n",
       "  58,\n",
       "  1,\n",
       "  65,\n",
       "  60,\n",
       "  2,\n",
       "  50,\n",
       "  52,\n",
       "  63,\n",
       "  48,\n",
       "  1,\n",
       "  8,\n",
       "  61,\n",
       "  2,\n",
       "  87,\n",
       "  2,\n",
       "  48,\n",
       "  60,\n",
       "  65,\n",
       "  64,\n",
       "  60,\n",
       "  52,\n",
       "  50,\n",
       "  65,\n",
       "  83,\n",
       "  52,\n",
       "  87,\n",
       "  2,\n",
       "  2,\n",
       "  56,\n",
       "  48,\n",
       "  58,\n",
       "  61,\n",
       "  64,\n",
       "  65,\n",
       "  61,\n",
       "  67,\n",
       "  60,\n",
       "  64,\n",
       "  66,\n",
       "  61,\n",
       "  52,\n",
       "  61,\n",
       "  54,\n",
       "  61,\n",
       "  2,\n",
       "  52,\n",
       "  67,\n",
       "  65,\n",
       "  60,\n",
       "  56,\n",
       "  61,\n",
       "  61,\n",
       "  2,\n",
       "  1,\n",
       "  48,\n",
       "  52,\n",
       "  37,\n",
       "  48,\n",
       "  56,\n",
       "  61,\n",
       "  2,\n",
       "  65,\n",
       "  2,\n",
       "  48,\n",
       "  50,\n",
       "  56,\n",
       "  2,\n",
       "  61,\n",
       "  70,\n",
       "  51,\n",
       "  61,\n",
       "  58,\n",
       "  70,\n",
       "  2,\n",
       "  61,\n",
       "  48,\n",
       "  65,\n",
       "  48,\n",
       "  2,\n",
       "  70,\n",
       "  61,\n",
       "  52,\n",
       "  62,\n",
       "  52,\n",
       "  52,\n",
       "  64,\n",
       "  60,\n",
       "  56,\n",
       "  52,\n",
       "  58,\n",
       "  60,\n",
       "  2,\n",
       "  65,\n",
       "  58,\n",
       "  48,\n",
       "  56,\n",
       "  66,\n",
       "  59,\n",
       "  84,\n",
       "  61,\n",
       "  2,\n",
       "  52,\n",
       "  2,\n",
       "  2,\n",
       "  61,\n",
       "  66,\n",
       "  64,\n",
       "  2,\n",
       "  67,\n",
       "  2,\n",
       "  64,\n",
       "  8,\n",
       "  60,\n",
       "  2,\n",
       "  56,\n",
       "  2,\n",
       "  60,\n",
       "  60,\n",
       "  48,\n",
       "  55,\n",
       "  2,\n",
       "  2,\n",
       "  58,\n",
       "  58,\n",
       "  60,\n",
       "  87,\n",
       "  58,\n",
       "  65,\n",
       "  49,\n",
       "  52,\n",
       "  2,\n",
       "  2,\n",
       "  52,\n",
       "  62,\n",
       "  48,\n",
       "  48,\n",
       "  66,\n",
       "  2,\n",
       "  60,\n",
       "  2,\n",
       "  56,\n",
       "  60,\n",
       "  51,\n",
       "  48,\n",
       "  67,\n",
       "  2,\n",
       "  58,\n",
       "  61,\n",
       "  67,\n",
       "  52,\n",
       "  62,\n",
       "  61,\n",
       "  52,\n",
       "  48,\n",
       "  52,\n",
       "  32,\n",
       "  32,\n",
       "  58,\n",
       "  60,\n",
       "  65,\n",
       "  48,\n",
       "  60,\n",
       "  61,\n",
       "  51,\n",
       "  64,\n",
       "  65,\n",
       "  70,\n",
       "  61,\n",
       "  60,\n",
       "  64,\n",
       "  52,\n",
       "  2,\n",
       "  56,\n",
       "  65,\n",
       "  61,\n",
       "  63,\n",
       "  61,\n",
       "  2,\n",
       "  52,\n",
       "  52,\n",
       "  65,\n",
       "  56,\n",
       "  61,\n",
       "  2,\n",
       "  65,\n",
       "  48,\n",
       "  60,\n",
       "  60,\n",
       "  51,\n",
       "  66,\n",
       "  63,\n",
       "  60,\n",
       "  52,\n",
       "  68,\n",
       "  52,\n",
       "  67,\n",
       "  48,\n",
       "  8,\n",
       "  61,\n",
       "  65,\n",
       "  2,\n",
       "  52,\n",
       "  67,\n",
       "  2,\n",
       "  52,\n",
       "  52,\n",
       "  48,\n",
       "  61,\n",
       "  58,\n",
       "  51,\n",
       "  56,\n",
       "  8,\n",
       "  59,\n",
       "  49,\n",
       "  61,\n",
       "  61,\n",
       "  2,\n",
       "  56,\n",
       "  48,\n",
       "  70,\n",
       "  50,\n",
       "  48,\n",
       "  50,\n",
       "  65,\n",
       "  52,\n",
       "  2,\n",
       "  67,\n",
       "  64,\n",
       "  62,\n",
       "  48,\n",
       "  51,\n",
       "  63,\n",
       "  52,\n",
       "  48,\n",
       "  70,\n",
       "  58,\n",
       "  2,\n",
       "  2,\n",
       "  56,\n",
       "  8,\n",
       "  52,\n",
       "  48,\n",
       "  50,\n",
       "  64,\n",
       "  2,\n",
       "  63,\n",
       "  61,\n",
       "  1,\n",
       "  56,\n",
       "  60,\n",
       "  65,\n",
       "  1,\n",
       "  48,\n",
       "  65,\n",
       "  64,\n",
       "  56,\n",
       "  48,\n",
       "  61,\n",
       "  58,\n",
       "  1,\n",
       "  2,\n",
       "  58,\n",
       "  2,\n",
       "  50,\n",
       "  48,\n",
       "  60,\n",
       "  63,\n",
       "  63,\n",
       "  61,\n",
       "  70,\n",
       "  56,\n",
       "  64,\n",
       "  67,\n",
       "  50,\n",
       "  67,\n",
       "  2,\n",
       "  60,\n",
       "  65,\n",
       "  64,\n",
       "  64,\n",
       "  2,\n",
       "  56,\n",
       "  67,\n",
       "  65,\n",
       "  65,\n",
       "  58,\n",
       "  56,\n",
       "  61,\n",
       "  58,\n",
       "  50,\n",
       "  2,\n",
       "  61,\n",
       "  52,\n",
       "  2,\n",
       "  52,\n",
       "  48,\n",
       "  58,\n",
       "  53,\n",
       "  52,\n",
       "  48,\n",
       "  51,\n",
       "  49,\n",
       "  61,\n",
       "  48,\n",
       "  60,\n",
       "  67,\n",
       "  61,\n",
       "  53,\n",
       "  60,\n",
       "  48,\n",
       "  51,\n",
       "  51,\n",
       "  2,\n",
       "  2,\n",
       "  55,\n",
       "  61,\n",
       "  66,\n",
       "  48,\n",
       "  60,\n",
       "  60,\n",
       "  61,\n",
       "  49,\n",
       "  61,\n",
       "  52,\n",
       "  56,\n",
       "  61,\n",
       "  2,\n",
       "  48,\n",
       "  64,\n",
       "  86,\n",
       "  56,\n",
       "  58,\n",
       "  51,\n",
       "  71,\n",
       "  86,\n",
       "  52,\n",
       "  61,\n",
       "  52,\n",
       "  48,\n",
       "  48,\n",
       "  66,\n",
       "  61,\n",
       "  60,\n",
       "  48,\n",
       "  64,\n",
       "  2,\n",
       "  56,\n",
       "  67,\n",
       "  52,\n",
       "  52,\n",
       "  61,\n",
       "  2,\n",
       "  65,\n",
       "  50,\n",
       "  64,\n",
       "  2,\n",
       "  64,\n",
       "  65,\n",
       "  68,\n",
       "  2,\n",
       "  65,\n",
       "  64,\n",
       "  50,\n",
       "  56,\n",
       "  48,\n",
       "  66,\n",
       "  61,\n",
       "  86,\n",
       "  2,\n",
       "  52,\n",
       "  48,\n",
       "  67,\n",
       "  10,\n",
       "  65,\n",
       "  62,\n",
       "  59,\n",
       "  65,\n",
       "  2,\n",
       "  61,\n",
       "  65,\n",
       "  65,\n",
       "  51,\n",
       "  2,\n",
       "  65,\n",
       "  61,\n",
       "  48,\n",
       "  58,\n",
       "  60,\n",
       "  66,\n",
       "  56,\n",
       "  52,\n",
       "  48,\n",
       "  48,\n",
       "  2,\n",
       "  61,\n",
       "  61,\n",
       "  52,\n",
       "  2,\n",
       "  61,\n",
       "  2,\n",
       "  52,\n",
       "  52,\n",
       "  2,\n",
       "  64,\n",
       "  52,\n",
       "  56,\n",
       "  52,\n",
       "  64,\n",
       "  61,\n",
       "  58,\n",
       "  65,\n",
       "  50,\n",
       "  67,\n",
       "  8,\n",
       "  2,\n",
       "  55,\n",
       "  70,\n",
       "  52,\n",
       "  48,\n",
       "  2,\n",
       "  48,\n",
       "  2,\n",
       "  62,\n",
       "  61,\n",
       "  51,\n",
       "  59,\n",
       "  52,\n",
       "  57,\n",
       "  2,\n",
       "  60,\n",
       "  65,\n",
       "  58,\n",
       "  62,\n",
       "  61,\n",
       "  2,\n",
       "  59,\n",
       "  65,\n",
       "  52,\n",
       "  61,\n",
       "  65,\n",
       "  62,\n",
       "  2,\n",
       "  2,\n",
       "  61,\n",
       "  2,\n",
       "  65,\n",
       "  58,\n",
       "  61,\n",
       "  48,\n",
       "  61,\n",
       "  66,\n",
       "  1,\n",
       "  59,\n",
       "  48,\n",
       "  64,\n",
       "  52,\n",
       "  54,\n",
       "  48,\n",
       "  87,\n",
       "  58,\n",
       "  2,\n",
       "  52,\n",
       "  66,\n",
       "  67,\n",
       "  70,\n",
       "  66,\n",
       "  52,\n",
       "  60,\n",
       "  62,\n",
       "  48,\n",
       "  67,\n",
       "  1,\n",
       "  61,\n",
       "  67,\n",
       "  38,\n",
       "  51,\n",
       "  2,\n",
       "  58,\n",
       "  65,\n",
       "  64,\n",
       "  54,\n",
       "  50,\n",
       "  59,\n",
       "  48,\n",
       "  66,\n",
       "  62,\n",
       "  49,\n",
       "  87,\n",
       "  48,\n",
       "  48,\n",
       "  59,\n",
       "  48,\n",
       "  62,\n",
       "  59,\n",
       "  51,\n",
       "  65,\n",
       "  48,\n",
       "  58,\n",
       "  48,\n",
       "  67,\n",
       "  60,\n",
       "  48,\n",
       "  67,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  50,\n",
       "  70,\n",
       "  64,\n",
       "  48,\n",
       "  60,\n",
       "  58,\n",
       "  52,\n",
       "  48,\n",
       "  2,\n",
       "  2,\n",
       "  60,\n",
       "  60,\n",
       "  2,\n",
       "  68,\n",
       "  59,\n",
       "  52,\n",
       "  2,\n",
       "  58,\n",
       "  2,\n",
       "  58,\n",
       "  2,\n",
       "  51,\n",
       "  2,\n",
       "  58,\n",
       "  87,\n",
       "  65,\n",
       "  61,\n",
       "  56,\n",
       "  52,\n",
       "  2,\n",
       "  65,\n",
       "  66,\n",
       "  48,\n",
       "  51,\n",
       "  63,\n",
       "  50,\n",
       "  52,\n",
       "  61,\n",
       "  51,\n",
       "  65,\n",
       "  52,\n",
       "  58,\n",
       "  51,\n",
       "  2,\n",
       "  66,\n",
       "  56,\n",
       "  2,\n",
       "  61,\n",
       "  65,\n",
       "  51,\n",
       "  61,\n",
       "  48,\n",
       "  48,\n",
       "  61,\n",
       "  52,\n",
       "  56,\n",
       "  64,\n",
       "  8,\n",
       "  71,\n",
       "  67,\n",
       "  64,\n",
       "  65,\n",
       "  65,\n",
       "  66,\n",
       "  20,\n",
       "  65,\n",
       "  68,\n",
       "  8,\n",
       "  58,\n",
       "  59,\n",
       "  64,\n",
       "  52,\n",
       "  2,\n",
       "  60,\n",
       "  1,\n",
       "  52,\n",
       "  48,\n",
       "  64,\n",
       "  70,\n",
       "  48,\n",
       "  68,\n",
       "  67,\n",
       "  64,\n",
       "  2,\n",
       "  64,\n",
       "  48,\n",
       "  66,\n",
       "  ...])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T18:40:02.459423Z",
     "start_time": "2019-01-07T18:40:01.970956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 48, 60, ...,  2,  2,  2])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(c1_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T17:59:54.139647Z",
     "start_time": "2019-01-07T17:59:51.539146Z"
    }
   },
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat)\n",
    "x2 = np.stack(c2_dat)\n",
    "x3 = np.stack(c3_dat)\n",
    "x4 = np.stack(c4_dat)\n",
    "x5 = np.stack(c5_dat)\n",
    "x6 = np.stack(c6_dat)\n",
    "x7 = np.stack(c7_dat)\n",
    "x8 = np.stack(c8_dat)\n",
    "x9 = np.stack(c9_dat)\n",
    "x10 = np.stack(c10_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:07:14.798316Z",
     "start_time": "2019-01-07T19:07:14.531483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 36, 64, ..., 48,  2, 62],\n",
       "       [48, 64, 66, ..., 58,  2, 56],\n",
       "       [60, 54, 52, ..., 61,  2, 55],\n",
       "       ...,\n",
       "       [ 2, 63, 67, ...,  2, 60, 61],\n",
       "       [ 2, 62, 48, ..., 48, 60,  8],\n",
       "       [ 2, 65, 52, ...,  1, 48, 51]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([x1,x2,x3,x4,x5,x6,x7,x8,x9,x10], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:14:32.023792Z",
     "start_time": "2019-01-06T17:14:31.622024Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.stack(c11_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 4 inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T19:49:43.717926Z",
     "start_time": "2019-01-04T19:49:43.578020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2, 48,  2, 54]),\n",
       " array([36,  2, 51, 52]),\n",
       " array([64, 62, 52, 60]),\n",
       " array([56, 48, 58, 56]),\n",
       " array([59, 64,  2, 61]),\n",
       " array([52, 66, 56, 65]))"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4],x4[:4], x5[:4], x6[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T19:49:45.056156Z",
     "start_time": "2019-01-04T19:49:44.928228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48,  2, 54,  2])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:14:45.339098Z",
     "start_time": "2019-01-06T17:14:45.182191Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((159999,), (159999,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a size for our hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:14:19.628868Z",
     "start_time": "2019-01-07T19:14:19.354039Z"
    }
   },
   "outputs": [],
   "source": [
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of latent factors to create (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:14:21.044411Z",
     "start_time": "2019-01-07T19:14:20.792544Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fac = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:14:22.639884Z",
     "start_time": "2019-01-07T19:14:22.112537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(20, 30)\n",
    "input = torch.randn(128, 20)\n",
    "output = m(input)\n",
    "print(output.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:14:24.060628Z",
     "start_time": "2019-01-07T19:14:23.808760Z"
    }
   },
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "\n",
    "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "\n",
    "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        h = V(torch.zeros(in1.size()))\n",
    "        h = torch.tanh(self.l_hidden(h+in1))\n",
    "        h = torch.tanh(self.l_hidden(h+in2))\n",
    "        h = torch.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo LSTM propio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:14:28.013116Z",
     "start_time": "2019-01-07T19:14:27.753250Z"
    }
   },
   "outputs": [],
   "source": [
    "class Char3LSTMModel(nn.Module):\n",
    "    def __init__(self,vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        \n",
    "        # Matriz de pesos para input gate\n",
    "        self.l_xi = nn.Linear(n_hidden, n_hidden)\n",
    "                \n",
    "        # Matriz de pesos para forget gate f(t)\n",
    "        self.l_xf = nn.Linear(n_hidden, n_hidden)\n",
    "                \n",
    "        # Matriz dea  gate g(t)\n",
    "        self.l_xg = nn.Linear(n_hidden, n_hidden)\n",
    "                \n",
    "        # Matriz de pesos para output gate i(t)\n",
    "        self.l_xo = nn.Linear(n_hidden, n_hidden)\n",
    "        \n",
    "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "               \n",
    "    def forward(self,*cs):\n",
    "        #Embeddings\n",
    "        \n",
    "        #in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        #in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        #in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        bs = cs[0].size()[0]\n",
    "        h = V(torch.zeros([bs,n_hidden]))\n",
    "        c = V(torch.ones([bs,n_hidden]))\n",
    "         \n",
    "        for car in cs:\n",
    "            inc = F.relu(self.l_in(self.e(car)))\n",
    "            h,c = self.cellLSTM(inc,h,c)\n",
    "        #pdb.set_trace()           \n",
    "        return F.log_softmax(self.l_out(h))\n",
    "    \n",
    "    def cellLSTM(self,c_emb,h1,c1):\n",
    "        it = F.logsigmoid(self.l_xi(c_emb+h1))\n",
    "        ft = F.logsigmoid(self.l_xf(c_emb+h1))\n",
    "        gt = torch.tanh(self.l_xg(c_emb+h1))\n",
    "        c = torch.mul(ft,c1) + torch.mul(it,gt)\n",
    "        h1 =torch.mul(F.logsigmoid(self.l_xo(c_emb+h1)),torch.tanh(c1))\n",
    "        return h1,c1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:15:52.742979Z",
     "start_time": "2019-01-07T19:15:52.482130Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2, 36, 64, ..., 59, 52, 64],\n",
       "       [48, 64, 66, ...,  2, 51, 52],\n",
       "       [60, 54, 52, ..., 56, 61, 65],\n",
       "       ...,\n",
       "       [ 2, 63, 67, ...,  2, 70, 48],\n",
       "       [ 2, 62, 48, ..., 52, 50, 84],\n",
       "       [ 2, 65, 52, ..., 53, 67, 52]])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([x1,x2,x3,x4,x5,x6,x7], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:15:09.837464Z",
     "start_time": "2019-01-07T19:15:09.370689Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-229-5c1366197350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3,x4,x5,x6,x7], axis=1), y, bs=512)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mColumnarModelData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\column_data.py\u001b[0m in \u001b[0;36mfrom_arrays\u001b[1;34m(cls, path, val_idxs, xs, y, is_reg, is_multi, bs, test_xs, shuffle)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfrom_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_idxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_xs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_xs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_xs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrn_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_by_idx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_idxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mtest_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPassthruDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_xs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_xs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_reg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_multi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtest_xs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         return cls(path, PassthruDataset(*(trn_xs.T), trn_y, is_reg=is_reg, is_multi=is_multi),\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\dataset.py\u001b[0m in \u001b[0;36msplit_by_idx\u001b[1;34m(idxs, *a)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[0mmask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "#md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3,x4,x5,x6,x7], axis=1), y, bs=512)\n",
    "md = ColumnarModelData.from_arrays('.', [-1], x, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:15:29.808812Z",
     "start_time": "2019-01-06T17:15:29.516683Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 36, 64],\n",
       "        [48, 64, 66],\n",
       "        [60, 54, 52],\n",
       "        ...,\n",
       "        [ 2, 63, 67],\n",
       "        [ 2, 62, 48],\n",
       "        [ 2, 65, 52]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T(np.stack([x1,x2,x3])).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:15:30.767245Z",
     "start_time": "2019-01-06T17:15:30.631323Z"
    }
   },
   "outputs": [],
   "source": [
    "a=np.stack([x1,x2,x3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:15:31.717699Z",
     "start_time": "2019-01-06T17:15:31.580778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159999"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:15:32.685142Z",
     "start_time": "2019-01-06T17:15:32.546222Z"
    }
   },
   "outputs": [],
   "source": [
    "#m = Char3Model(vocab_size, n_fac)\n",
    "m=Char3LSTMModel(vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:15:33.996385Z",
     "start_time": "2019-01-06T17:15:33.485680Z"
    }
   },
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:15:35.039786Z",
     "start_time": "2019-01-06T17:15:34.895869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:15:36.219105Z",
     "start_time": "2019-01-06T17:15:36.061196Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:21:18.643848Z",
     "start_time": "2019-01-06T17:15:38.581744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522d071462f74274b1a7fe8551f84a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                 \n",
      "    0      2.947117   2.910501  \n",
      "    1      2.915558   2.720752                                                 \n",
      "    2      2.871926   3.176235                                                 \n",
      "    3      2.847276   3.17685                                                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.176849842071533]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T19:42:56.465052Z",
     "start_time": "2019-01-04T19:42:56.331117Z"
    }
   },
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T19:42:57.452035Z",
     "start_time": "2019-01-04T19:42:57.307119Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3046, -1.1587, -1.0664, -1.2803, -1.1526, -1.1849, -1.1822,\n",
       "          -1.1771, -1.1631, -0.9821, -0.9688, -1.2420, -0.9863, -1.2939,\n",
       "          -1.3495, -1.2061, -1.3813, -1.1702, -1.1900, -1.1088, -1.1725,\n",
       "          -1.2301, -1.2655, -1.3613, -1.4422, -1.3442, -1.2309, -1.3043,\n",
       "          -1.1488, -1.1908, -1.2645, -1.1694, -1.2066, -1.2585, -1.3207,\n",
       "          -1.3638, -1.1173, -1.1077, -0.7104, -0.9964, -1.2207, -1.2727,\n",
       "          -0.4169, -1.0494, -1.0266, -0.8931, -0.6190, -1.0928, -1.2901,\n",
       "          -1.1895, -1.2537, -0.6208, -1.1123, -1.0520, -1.2349, -1.2540,\n",
       "          -1.1196, -0.9442, -1.2352, -1.4541, -1.1856, -1.2946, -1.3593,\n",
       "          -1.3216, -1.1350, -1.3780, -1.1796, -1.1190, -0.9059, -0.9626,\n",
       "          -0.8730, -1.1779, -1.0555, -1.1784, -1.0857],\n",
       "         [-1.3046, -1.1587, -1.0664, -1.2803, -1.1526, -1.1849, -1.1822,\n",
       "          -1.1771, -1.1631, -0.9821, -0.9688, -1.2420, -0.9863, -1.2939,\n",
       "          -1.3495, -1.2061, -1.3813, -1.1702, -1.1900, -1.1088, -1.1725,\n",
       "          -1.2301, -1.2655, -1.3613, -1.4422, -1.3442, -1.2309, -1.3043,\n",
       "          -1.1488, -1.1908, -1.2645, -1.1694, -1.2066, -1.2585, -1.3207,\n",
       "          -1.3638, -1.1173, -1.1077, -0.7104, -0.9964, -1.2207, -1.2727,\n",
       "          -0.4169, -1.0494, -1.0266, -0.8931, -0.6190, -1.0928, -1.2901,\n",
       "          -1.1895, -1.2537, -0.6208, -1.1123, -1.0520, -1.2349, -1.2540,\n",
       "          -1.1196, -0.9442, -1.2352, -1.4541, -1.1856, -1.2946, -1.3593,\n",
       "          -1.3216, -1.1350, -1.3780, -1.1796, -1.1190, -0.9059, -0.9626,\n",
       "          -0.8730, -1.1779, -1.0555, -1.1784, -1.0857],\n",
       "         [-1.3046, -1.1587, -1.0664, -1.2803, -1.1526, -1.1849, -1.1822,\n",
       "          -1.1771, -1.1631, -0.9821, -0.9688, -1.2420, -0.9863, -1.2939,\n",
       "          -1.3495, -1.2061, -1.3813, -1.1702, -1.1900, -1.1088, -1.1725,\n",
       "          -1.2301, -1.2655, -1.3613, -1.4422, -1.3442, -1.2309, -1.3043,\n",
       "          -1.1488, -1.1908, -1.2645, -1.1694, -1.2066, -1.2585, -1.3207,\n",
       "          -1.3638, -1.1173, -1.1077, -0.7104, -0.9964, -1.2207, -1.2727,\n",
       "          -0.4169, -1.0494, -1.0266, -0.8931, -0.6190, -1.0928, -1.2901,\n",
       "          -1.1895, -1.2537, -0.6208, -1.1123, -1.0520, -1.2349, -1.2540,\n",
       "          -1.1196, -0.9442, -1.2352, -1.4541, -1.1856, -1.2946, -1.3593,\n",
       "          -1.3216, -1.1350, -1.3780, -1.1796, -1.1190, -0.9059, -0.9626,\n",
       "          -0.8730, -1.1779, -1.0555, -1.1784, -1.0857]],\n",
       "\n",
       "        [[-0.9854, -1.0717, -1.0744, -1.0036, -1.1385, -1.0332, -1.0516,\n",
       "          -1.0317, -1.0032, -1.1629, -1.1047, -1.1265, -1.1740, -1.1333,\n",
       "          -0.9194, -1.0103, -1.0551, -1.0670, -1.0064, -1.1078, -1.1172,\n",
       "          -1.0410, -1.0376, -1.0015, -0.9683, -1.0814, -1.0584, -1.0179,\n",
       "          -1.0634, -1.0480, -1.0288, -1.0767, -1.1246, -1.0193, -1.0183,\n",
       "          -1.0273, -1.1016, -1.0897, -1.5118, -1.1448, -0.9668, -1.0520,\n",
       "          -1.8357, -1.1728, -1.1530, -1.3031, -1.7134, -1.1340, -0.9298,\n",
       "          -0.9611, -0.8957, -1.8411, -0.9994, -1.0565, -0.9581, -0.8225,\n",
       "          -1.1167, -1.3575, -1.0515, -0.9594, -1.0040, -1.0340, -0.9935,\n",
       "          -1.0227, -1.0769, -1.0515, -1.0852, -1.0176, -1.2567, -1.1659,\n",
       "          -1.2744, -1.0269, -1.2971, -1.0372, -1.0590],\n",
       "         [-0.9854, -1.0717, -1.0744, -1.0036, -1.1385, -1.0332, -1.0516,\n",
       "          -1.0317, -1.0032, -1.1629, -1.1047, -1.1265, -1.1740, -1.1333,\n",
       "          -0.9194, -1.0103, -1.0551, -1.0670, -1.0064, -1.1078, -1.1172,\n",
       "          -1.0410, -1.0376, -1.0015, -0.9683, -1.0814, -1.0584, -1.0179,\n",
       "          -1.0634, -1.0480, -1.0288, -1.0767, -1.1246, -1.0193, -1.0183,\n",
       "          -1.0273, -1.1016, -1.0897, -1.5118, -1.1448, -0.9668, -1.0520,\n",
       "          -1.8357, -1.1728, -1.1530, -1.3031, -1.7134, -1.1340, -0.9298,\n",
       "          -0.9611, -0.8957, -1.8411, -0.9994, -1.0565, -0.9581, -0.8225,\n",
       "          -1.1167, -1.3575, -1.0515, -0.9594, -1.0040, -1.0340, -0.9935,\n",
       "          -1.0227, -1.0769, -1.0515, -1.0852, -1.0176, -1.2567, -1.1659,\n",
       "          -1.2744, -1.0269, -1.2971, -1.0372, -1.0590],\n",
       "         [-0.9854, -1.0717, -1.0744, -1.0036, -1.1385, -1.0332, -1.0516,\n",
       "          -1.0317, -1.0032, -1.1629, -1.1047, -1.1265, -1.1740, -1.1333,\n",
       "          -0.9194, -1.0103, -1.0551, -1.0670, -1.0064, -1.1078, -1.1172,\n",
       "          -1.0410, -1.0376, -1.0015, -0.9683, -1.0814, -1.0584, -1.0179,\n",
       "          -1.0634, -1.0480, -1.0288, -1.0767, -1.1246, -1.0193, -1.0183,\n",
       "          -1.0273, -1.1016, -1.0897, -1.5118, -1.1448, -0.9668, -1.0520,\n",
       "          -1.8357, -1.1728, -1.1530, -1.3031, -1.7134, -1.1340, -0.9298,\n",
       "          -0.9611, -0.8957, -1.8411, -0.9994, -1.0565, -0.9581, -0.8225,\n",
       "          -1.1167, -1.3575, -1.0515, -0.9594, -1.0040, -1.0340, -0.9935,\n",
       "          -1.0227, -1.0769, -1.0515, -1.0852, -1.0176, -1.2567, -1.1659,\n",
       "          -1.2744, -1.0269, -1.2971, -1.0372, -1.0590]],\n",
       "\n",
       "        [[-1.0344, -1.0680, -1.1575, -1.0343, -1.0109, -1.0836, -1.0671,\n",
       "          -1.0923, -1.1370, -1.1620, -1.2408, -0.9493, -1.1459, -0.9068,\n",
       "          -1.0733, -1.0891, -0.9149, -1.0623, -1.1079, -1.0795, -1.0128,\n",
       "          -1.0367, -1.0117, -0.9772, -0.9574, -0.9160, -1.0190, -1.0016,\n",
       "          -1.0855, -1.0631, -1.0212, -1.0534, -0.9781, -1.0354, -0.9893,\n",
       "          -0.9510, -1.0773, -1.0986, -1.2447, -1.1631, -1.1249, -0.9924,\n",
       "          -1.7070, -1.0778, -1.1206, -1.1427, -1.2684, -1.0701, -1.1083,\n",
       "          -1.1610, -1.1835, -1.1913, -1.1937, -1.1937, -1.1223, -1.2898,\n",
       "          -1.0607, -1.0393, -1.0221, -0.9590, -1.1147, -0.9931, -0.9865,\n",
       "          -0.9844, -1.0849, -0.9200, -1.0363, -1.1650, -1.1672, -1.1827,\n",
       "          -1.1950, -1.0968, -0.9712, -1.0854, -1.1535],\n",
       "         [-1.0344, -1.0680, -1.1575, -1.0343, -1.0109, -1.0836, -1.0671,\n",
       "          -1.0923, -1.1370, -1.1620, -1.2408, -0.9493, -1.1459, -0.9068,\n",
       "          -1.0733, -1.0891, -0.9149, -1.0623, -1.1079, -1.0795, -1.0128,\n",
       "          -1.0367, -1.0117, -0.9772, -0.9574, -0.9160, -1.0190, -1.0016,\n",
       "          -1.0855, -1.0631, -1.0212, -1.0534, -0.9781, -1.0354, -0.9893,\n",
       "          -0.9510, -1.0773, -1.0986, -1.2447, -1.1631, -1.1249, -0.9924,\n",
       "          -1.7070, -1.0778, -1.1206, -1.1427, -1.2684, -1.0701, -1.1083,\n",
       "          -1.1610, -1.1835, -1.1913, -1.1937, -1.1937, -1.1223, -1.2898,\n",
       "          -1.0607, -1.0393, -1.0221, -0.9590, -1.1147, -0.9931, -0.9865,\n",
       "          -0.9844, -1.0849, -0.9200, -1.0363, -1.1650, -1.1672, -1.1827,\n",
       "          -1.1950, -1.0968, -0.9712, -1.0854, -1.1535],\n",
       "         [-1.0344, -1.0680, -1.1575, -1.0343, -1.0109, -1.0836, -1.0671,\n",
       "          -1.0923, -1.1370, -1.1620, -1.2408, -0.9493, -1.1459, -0.9068,\n",
       "          -1.0733, -1.0891, -0.9149, -1.0623, -1.1079, -1.0795, -1.0128,\n",
       "          -1.0367, -1.0117, -0.9772, -0.9574, -0.9160, -1.0190, -1.0016,\n",
       "          -1.0855, -1.0631, -1.0212, -1.0534, -0.9781, -1.0354, -0.9893,\n",
       "          -0.9510, -1.0773, -1.0986, -1.2447, -1.1631, -1.1249, -0.9924,\n",
       "          -1.7070, -1.0778, -1.1206, -1.1427, -1.2684, -1.0701, -1.1083,\n",
       "          -1.1610, -1.1835, -1.1913, -1.1937, -1.1937, -1.1223, -1.2898,\n",
       "          -1.0607, -1.0393, -1.0221, -0.9590, -1.1147, -0.9931, -0.9865,\n",
       "          -0.9844, -1.0849, -0.9200, -1.0363, -1.1650, -1.1672, -1.1827,\n",
       "          -1.1950, -1.0968, -0.9712, -1.0854, -1.1535]]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(T([[41,1,3]]).t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T19:43:10.120878Z",
     "start_time": "2019-01-04T19:42:59.628935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8bdd7a354b49bfa672f4232d18af07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                                 \n",
      "    0      2.385388   2.760971  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.7609708309173584]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:21:24.153031Z",
     "start_time": "2019-01-06T17:21:24.012112Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    #pdb.set_trace()\n",
    "    idxs = T(np.array([char_indices[c] for c in inp])).view(1,-1).t()\n",
    "    \n",
    "    #pdb.set_trace()\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    #i = np.argmax(p.view(-1).detach().numpy())\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:21:43.923137Z",
     "start_time": "2019-01-06T17:21:43.756251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('don quijot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:21:51.000604Z",
     "start_time": "2019-01-06T17:21:50.867696Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T17:22:51.055469Z",
     "start_time": "2019-01-06T17:22:49.675282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'el perro da                                                                                                                                                                                                                                                                                                                                                                                                               '"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('el perro d',400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T19:31:25.532661Z",
     "start_time": "2019-01-04T19:31:25.398733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-04T19:31:27.235861Z",
     "start_time": "2019-01-04T19:31:27.102938Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('and')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first RNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the size of our unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(c_in_dat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each column below is one series of 8 characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this is the next character after each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(idx)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    # This is an RNN!\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden))\n",
    "        for c in cs:\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopModel(vocab_size, n_fac)\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden)\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden))\n",
    "        for c in cs:\n",
    "            inp = torch.cat((h, self.e(c)), 1)\n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = torch.tanh(self.l_hidden(inp))#   F.tanh(self.l_hidden(inp))\n",
    "            #h = F.tanh(self.l_hidden(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopConcatModel(vocab_size, n_fac)\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('en un lu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, n_fac)\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take non-overlapping sets of characters this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(idx)-cs-1, cs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the exact same thing, offset by 1, as our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(c_in_dat)\n",
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.stack(c_out_dat)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xst,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size()\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)\n",
    "    return F.nll_loss(inp.view(-1,nh), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity init!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data\n",
    "\n",
    "from fastai.nlp import *\n",
    "from fastai.lm_rnn import *\n",
    "\n",
    "PATH='data/nietzsche/'\n",
    "\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "\n",
    "# Note: The student needs to practice her shell skills and prepare her own dataset before proceeding:\n",
    "# - trn/trn.txt (first 80% of nietzsche.txt)\n",
    "# - val/val.txt (last 20% of nietzsche.txt)\n",
    "\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls {PATH}trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "\n",
    "len(md.trn_dl), md.nt, len(md.trn_ds), len(md.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        self.vocab_size = vocab_size\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "\n",
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the pytorch source\n",
    "\n",
    "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp = []\n",
    "        o = self.h\n",
    "        for c in cs: \n",
    "            o = self.rnn(self.e(c), o)\n",
    "            outp.append(o)\n",
    "        outp = self.l_out(torch.stack(outp))\n",
    "        self.h = repackage_var(o)\n",
    "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-29T12:44:52.095639Z",
     "start_time": "2018-12-29T12:44:51.942741Z"
    }
   },
   "outputs": [],
   "source": [
    "??nn.LSTMCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the pytorch source code - for reference\n",
    "\n",
    "def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    gi = F.linear(input, w_ih, b_ih)\n",
    "    gh = F.linear(hidden, w_hh, b_hh)\n",
    "    i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "    h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "\n",
    "    resetgate = F.sigmoid(i_r + h_r)\n",
    "    inputgate = F.sigmoid(i_i + h_i)\n",
    "    newgate = F.tanh(i_n + resetgate * h_n)\n",
    "    return newgate + inputgate * (hidden - newgate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
    "\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 6, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 3, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import sgdr\n",
    "\n",
    "n_hidden=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()\n",
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]\n",
    "fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_next_n('for thos', 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
